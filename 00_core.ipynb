{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Image scraping library for creating deep learning datasets. Uses DuckDuckGo, as the API for searching has more options and better results than the alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# scraping\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from enum import Enum\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# other\n",
    "from PIL import Image as PImage\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search filtering\n",
    "\n",
    "The scrape/search functions can use the following enums as filters for searches. By default the results **should be** square photos. This is what's requested from DDG. Sometimes results may not be quite what you've requested (eg: you may get a bit of clipart or something more or less square but not exactly). No checks are done on what comes back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "class ImgSize(Enum):\n",
    "  Thumbs=\"\"\n",
    "  Small=\"Small\"\n",
    "  Medium=\"Medium\"\n",
    "  Large=\"Large\"\n",
    "  Wallpaper=\"Wallpaper\"\n",
    "\n",
    "class ImgType(Enum):\n",
    "  All=\"\"\n",
    "  Photo=\"photo\"\n",
    "  Clipart=\"clipart\"\n",
    "  Gif=\"gif\"\n",
    "  Transparent=\"transparent\"\n",
    "\n",
    "class ImgLayout(Enum):\n",
    "  All=\"\"\n",
    "  Square=\"Square\"\n",
    "  Tall=\"Tall\"\n",
    "  Wide=\"Wide\"\n",
    "  \n",
    "class ImgColor(Enum):\n",
    "  All=\"\"\n",
    "  Color=\"color\"\n",
    "  Monochrome=\"Monochrome\"\n",
    "  Red=\"Red\"\n",
    "  Orange=\"Orange\"\n",
    "  Yellow=\"Yellow\"\n",
    "  Green=\"Green\"\n",
    "  Blue=\"Blue\"\n",
    "  Purple=\"Purple\"\n",
    "  Pink=\"Pink\" \n",
    "  Brown=\"Brown\"\n",
    "  Black=\"Black\" \n",
    "  Gray=\"Gray\" \n",
    "  Teal=\"Teal\"\n",
    "  White=\"White\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def duckduckgo_scrape_urls(keywords: str, max_results: int, \n",
    "                           img_size: ImgSize=ImgSize.Thumbs, \n",
    "                           img_type: ImgType=ImgType.Photo,\n",
    "                           img_layout: ImgLayout=ImgLayout.Square,\n",
    "                           img_color: ImgColor=ImgColor.All) -> list:\n",
    "  '''scrape urls from duckduckgo image search'''\n",
    "  BASE_URL = 'https://duckduckgo.com/'\n",
    "  params = {\n",
    "    'q': keywords\n",
    "  };\n",
    "  results = 0\n",
    "  links = []\n",
    "\n",
    "  resp = requests.post(BASE_URL, data=params)\n",
    "  match = re.search(r'vqd=([\\d-]+)\\&', resp.text, re.M|re.I)\n",
    "  assert match is not None, \"Failed to obtain search token\"\n",
    "\n",
    "  HEADERS = {\n",
    "      'authority': 'duckduckgo.com',\n",
    "      'accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "      'sec-fetch-dest': 'empty',\n",
    "      'x-requested-with': 'XMLHttpRequest',\n",
    "      'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36',\n",
    "      'sec-fetch-site': 'same-origin',\n",
    "      'sec-fetch-mode': 'cors',\n",
    "      'referer': 'https://duckduckgo.com/',\n",
    "      'accept-language': 'en-US,en;q=0.9',\n",
    "  }\n",
    "\n",
    "  filters = \"\"\n",
    "  if(img_size != ImgSize.Thumbs): filters +=  \"size:\" + img_size.name\n",
    "  filters += \",\"\n",
    "  if(img_type != ImgType.All): filters +=  \"type:\" + img_type.name\n",
    "  filters += \",\"\n",
    "  if(img_layout != ImgLayout.All): filters +=  \"layout:\" + img_layout.name\n",
    "  filters += \",\"\n",
    "  if(img_color != ImgColor.All): filters +=  \"color:\" + img_color.name\n",
    "  \n",
    "  PARAMS = (\n",
    "      ('l', 'us-en'),\n",
    "      ('o', 'json'),\n",
    "      ('q', keywords),\n",
    "      ('vqd', match.group(1)),\n",
    "      ('f', filters),\n",
    "      ('p', '1'),\n",
    "      ('v7exp', 'a'),\n",
    "  )\n",
    "\n",
    "  requestUrl = BASE_URL + \"i.js\"\n",
    "\n",
    "  while True:\n",
    "      while True:\n",
    "          try:\n",
    "              resp = requests.get(requestUrl, headers=HEADERS, params=PARAMS)\n",
    "              data = json.loads(resp.text)\n",
    "              break\n",
    "          except ValueError as e:\n",
    "              print(\"Hit request throttle, sleeping and retrying\")\n",
    "              time.sleep(5)\n",
    "              continue\n",
    "\n",
    "      #result[\"thumbnail\"] is normally big enough for most purposes\n",
    "      #result[\"width\"], result[\"height\"] are for the full size img in result[\"image\"]\n",
    "      #result[\"image\"] url to full size img on orig site (so may be less reliable) \n",
    "      #result[\"url\"], result[\"title\"].encode('utf-8') from the page the img came from\n",
    "      \n",
    "      for result in data[\"results\"]:\n",
    "        if(img_size == ImgSize.Thumbs): links.append(result[\"thumbnail\"])\n",
    "        else:                       links.append(result[\"image\"])\n",
    "\n",
    "        if(max_results is not None):\n",
    "          if(len(links) >= max_results) : return links\n",
    "\n",
    "      if \"next\" not in data:\n",
    "          #no next page, all done\n",
    "          return links\n",
    "\n",
    "      requestUrl = BASE_URL + data[\"next\"]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns a list of image URLs for this search. At the time of writing, this function will return up to 477 urls for a single search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPImage\n",
    "\n",
    "def display_img(url):\n",
    "    display(IPImage(url=url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://tse1.mm.bing.net/th?id=OIP.LR-2HW7P9ENbMGJ7cZTVGwHaHL&pid=Api',\n",
       " 'https://tse4.mm.bing.net/th?id=OIP.jgAbDJb9lY-p0Q83Q2xsCgHaI0&pid=Api',\n",
       " 'https://tse4.mm.bing.net/th?id=OIP.4g2txn6PXyuTbEXcJPI2qQHaIE&pid=Api']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = duckduckgo_scrape_urls(\"happy clowns\", max_results=3)\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://tse1.mm.bing.net/th?id=OIP.LR-2HW7P9ENbMGJ7cZTVGwHaHL&pid=Api\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_img(links[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that what gets returned by default is actually the image preview you see in the search results, not a thumbnail, and is quite a decent size, but comes from DDG. If you specify a size other than thumbs, then the URL returned is the original source URL, and is therefore more likely to fail a download attempt. The default (as shown above) should generally be sufficient for your needs.\n",
    "\n",
    "Since the parameters you use are likely to be the same across every image search within your dataset, if you plan on overriding the defaults, you can pass your parameters in using a dictionary like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://4.bp.blogspot.com/-GKGVUan6I3w/UOQtWCzichI/AAAAAAAANs0/mxox-FdrnRA/s1600/019.jpg',\n",
       " 'https://i.pinimg.com/736x/fa/fd/83/fafd8381375e3724bb2b2842ad175792--alessandra-ambrosio-dip-dyed.jpg',\n",
       " 'https://i.pinimg.com/originals/7e/a1/5b/7ea15b145096fd73aa95b4cf1ea2d35c.gif']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_results\": 3,\n",
    "    \"img_size\":    ImgSize.Medium, \n",
    "    \"img_type\":    ImgType.Photo,\n",
    "    \"img_layout\":  ImgLayout.All,\n",
    "    \"img_color\":   ImgColor.Purple\n",
    "}\n",
    "\n",
    "links = duckduckgo_scrape_urls(\"puppies\", **params)\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://4.bp.blogspot.com/-GKGVUan6I3w/UOQtWCzichI/AAAAAAAANs0/mxox-FdrnRA/s1600/019.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_img(links[0])\n",
    "# why? just why??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def rmtree(path: Union[str, Path]):\n",
    "    path = Path(path); assert path.is_dir()\n",
    "    for p in reversed(list(path.glob('**/*'))):\n",
    "        if p.is_file():  p.unlink()\n",
    "        elif p.is_dir(): p.rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `rmtree()` to scrub your downloaded images, either to create a new dataset or if you just want to \"reset\" and start over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd()/\"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_urls(path: Union[str, Path], links: list) -> list:\n",
    "  '''downloads urls into the given folder'''\n",
    "  if(len(links) == 0):\n",
    "    print(\"Nothing to download!\"); return\n",
    "\n",
    "  path = Path(path)\n",
    "  path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  print(\"Downloading\", len(links), \"results into\", path)\n",
    "  bar = widgets.IntProgress(0, 0, len(links) - 1)\n",
    "  display(bar)\n",
    "\n",
    "  i = 1\n",
    "  mk_fp = lambda i: path/(str(i).zfill(3) + \".jpg\")\n",
    "  is_file = lambda i: mk_fp(i).exists()\n",
    "  while is_file(i): i += 1 # don't overwrite previous searches\n",
    "  \n",
    "  results = []\n",
    "    \n",
    "  for link in links:\n",
    "      try:\n",
    "        resp = requests.get(link)      \n",
    "        fp = mk_fp(i)\n",
    "        fp.write_bytes(resp.content)\n",
    "\n",
    "        try:\n",
    "          img = PImage.open(fp)\n",
    "          img.verify()\n",
    "          img.close()\n",
    "          results.append(Path(fp))\n",
    "        except Exception as e:\n",
    "          # print(e)\n",
    "          print(fp, \"is invalid\")\n",
    "          fp.unlink()\n",
    "      except:\n",
    "        print(\"Exception occured while retrieving\", link)\n",
    "\n",
    "      i += 1\n",
    "      bar.value += 1\n",
    "\n",
    "  bar.bar_style = \"success\"\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloads a list of URLs into the given folder. Files will be saved as 001.jpg, 002.jpg etc but images already present will not be overwritten, so you can run multiple searches for the same label (eg: different genres of orchid all under one 'orchid' label) and file numbering will carry on from the last one on disc.\n",
    "\n",
    "Downloaded files will be checked for validity so you should never end up with corrupt images or truncated downloads.\n",
    "\n",
    "Returns a list of Path objects for succesfully downloaded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 3 results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\purple\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e78d3ad5884c3495da214c8f20eab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/purple/001.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/purple/002.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/purple/003.jpg')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_urls(root/\"purple\", links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def duckduckgo_search(path: Union[str, Path], label: str, keywords: str, max_results: int=100,\n",
    "                           img_size: ImgSize=ImgSize.Thumbs, \n",
    "                           img_type: ImgType=ImgType.Photo,\n",
    "                           img_layout: ImgLayout=ImgLayout.Square,\n",
    "                           img_color: ImgColor=ImgColor.All) -> list:\n",
    "  '''run a duckduckgo search and download the images'''\n",
    "  \n",
    "  print(\"Duckduckgo search:\", keywords)\n",
    "  links = duckduckgo_scrape_urls(keywords, max_results, img_size, img_type, img_layout, img_color)\n",
    "  return download_urls(Path(path)/label, links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a search and download the images. Returns a list of Path objects for the image files on disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duckduckgo search: nice clowns\n",
      "Downloading 3 results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\Nice\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14463424a1b445f2bbdf33414f442228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/001.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/002.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/003.jpg')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckduckgo_search(root, \"Nice\", \"nice clowns\", max_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a list of all the images downloaded across multiple searches you can do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duckduckgo search: nice clowns\n",
      "Downloading 3 results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\Nice\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e998abd51dde4f068885f976e4d43dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duckduckgo search: scary clowns\n",
      "Downloading 3 results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\Scary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c17d65075ad4b47b19f7b71f3c99bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/004.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/005.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/006.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Scary/001.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Scary/002.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Scary/003.jpg')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_results\": 3,\n",
    "    \"img_size\":    ImgSize.Thumbs, \n",
    "    \"img_type\":    ImgType.Photo,\n",
    "    \"img_layout\":  ImgLayout.Square,\n",
    "    \"img_color\":   ImgColor.All\n",
    "}\n",
    "\n",
    "imgs = []\n",
    "imgs.extend(duckduckgo_search(root, \"Nice\", \"nice clowns\", **params))\n",
    "imgs.extend(duckduckgo_search(root, \"Scary\", \"scary clowns\", **params))\n",
    "imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a CSV dataset\n",
    "\n",
    "If you want to create a very large dataset with a lot of images but don't want to store and distribute a very large file, you can create a CSV file containing URL/label pairs. Your users can then download the image files themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export                           \n",
    "def save_urls_to_csv(path: Union[str, Path], label: str, keywords: str, max_results: int=100,\n",
    "                       img_size: ImgSize=ImgSize.Thumbs, \n",
    "                       img_type: ImgType=ImgType.Photo,\n",
    "                       img_layout: ImgLayout=ImgLayout.Square,\n",
    "                       img_color: ImgColor=ImgColor.All) -> None:\n",
    "  '''run a search and concat the urls to a csv'''\n",
    "  path = Path(path)\n",
    "  if(path.exists() == False):\n",
    "    df = pd.DataFrame(columns=[\"URL\", \"Label\"])\n",
    "    df.to_csv(path, index=False)\n",
    "    \n",
    "  urls = duckduckgo_scrape_urls(keywords, max_results, img_size, img_type, img_layout, img_color)\n",
    "  \n",
    "  rows = []\n",
    "  for url in urls: rows.append({\"URL\":url, \"Label\":label})\n",
    "    \n",
    "  df = pd.concat([pd.read_csv(path), pd.DataFrame(rows)]) \n",
    "  df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = root/\"clowns.csv\"\n",
    "save_urls_to_csv(csv, \"Nice\", \"nice clowns\", max_results=5)\n",
    "save_urls_to_csv(csv, \"Scary\", \"scary clowns\", max_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://tse4.mm.bing.net/th?id=OIP.uFX0ybAs0Hi...</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://tse4.mm.bing.net/th?id=OIP.s3Ie8ax_Fa6...</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://tse1.mm.bing.net/th?id=OIP.lwC5ho3Ta-T...</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://tse4.mm.bing.net/th?id=OIP.glEf94S1eD0...</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://tse1.mm.bing.net/th?id=OIP.9lCTTlLeQV9...</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://tse3.mm.bing.net/th?id=OIP.zMsnePdSfSb...</td>\n",
       "      <td>Scary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://tse3.mm.bing.net/th?id=OIP.yhDrJ18seBC...</td>\n",
       "      <td>Scary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://tse1.mm.bing.net/th?id=OIP.y5tm55MMKcW...</td>\n",
       "      <td>Scary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://tse3.mm.bing.net/th?id=OIP.MWOP-aLPv8D...</td>\n",
       "      <td>Scary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://tse4.mm.bing.net/th?id=OIP.LOPx2ViR4-C...</td>\n",
       "      <td>Scary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  Label\n",
       "0  https://tse4.mm.bing.net/th?id=OIP.uFX0ybAs0Hi...   Nice\n",
       "1  https://tse4.mm.bing.net/th?id=OIP.s3Ie8ax_Fa6...   Nice\n",
       "2  https://tse1.mm.bing.net/th?id=OIP.lwC5ho3Ta-T...   Nice\n",
       "3  https://tse4.mm.bing.net/th?id=OIP.glEf94S1eD0...   Nice\n",
       "4  https://tse1.mm.bing.net/th?id=OIP.9lCTTlLeQV9...   Nice\n",
       "5  https://tse3.mm.bing.net/th?id=OIP.zMsnePdSfSb...  Scary\n",
       "6  https://tse3.mm.bing.net/th?id=OIP.yhDrJ18seBC...  Scary\n",
       "7  https://tse1.mm.bing.net/th?id=OIP.y5tm55MMKcW...  Scary\n",
       "8  https://tse3.mm.bing.net/th?id=OIP.MWOP-aLPv8D...  Scary\n",
       "9  https://tse4.mm.bing.net/th?id=OIP.LOPx2ViR4-C...  Scary"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_images_from_csv(path: Union[str, Path], csv: Union[str, Path], url_col: str=\"URL\", label_col: str=\"Label\"):\n",
    "    path = Path(path); csv = Path(csv);\n",
    "    \n",
    "    df = pd.read_csv(csv)\n",
    "    labels = df.Label.unique()\n",
    "    \n",
    "    for label in labels:\n",
    "        df_label = df.loc[df[label_col] == label]\n",
    "        urls = df_label[url_col].to_list()\n",
    "        download_urls(path/label, urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will (you've guessed it), download the image files from the CSV file we've just created. You can also supply column names if you want to use it on a CSV file created elsewhere with different names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 5 results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\Nice\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde295ff857e4681b8aa388de877582f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 5 results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\Scary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981cabd4f39e4601bb13ff0eb332473d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_images_from_csv(root, csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
